---
title: "lab_8"
author: "Daija Odom"
date: "11/15/2021"
output: html_document
---

```{r setup, include=FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

library(tidyverse)
library(corrplot)
library(stargazer)
library(broom)
library(modelsummary)
library(here)
```

## Read in data

```{r}
homes <- read_csv(here("data", "slo_homes.csv"))
```

A little bit of cleaning:

Make a subset called homes_sub that only contains observations (rows) where the city is:

- San Luis Obispo
- Arroyo Grande
- Atascadero
- Santa Maria-Orcutt

```{r}
# homes_sub <- homes %>% 
  # filter(City == c("San Luis Obispo", "Arroyo Grande", "Atascadero", "Santa Maria-Orcutt")) 
# This is incorrect. While the code will run, it's telling R "I want you to look in each row in the city column" 
  
homes_sub <- homes %>% 
  filter(City %in% c("San Luis Obispo", "Arroyo Grande", "Atascadero", "Santa Maria-Orcutt")) 
 # after you run every step check your data sets by using unique(homes_sub$City) in the console
```

## Do a little exploring of our data

Summary statistics (home price, based on city and sale status):

- Find & return in a nice summary table the mean and standard deviation of home price, grouped by city and sale status.

```{r, include = FALSE, eval = FALSE}
homes_sub %>% 
  group_by(City, Status) %>% 
  summarize(mean_price = mean(Price, na.rm = TRUE),
            sd_price = sd(Price, na.rm = TRUE))

# after running the summary statistics and without doing anything further, start looking at your summary statistics based on what you think are the important variables (i.e. homes with foreclosures have lower prices than regular homes)

# Actually I don't even want to run this code set 'eval = FALSE' in the code chunk. (Will also help you figure out if that code chunk is the thing that won't allow you to knit)

ggplot(data = homes_sub, aes(x = Price)) +
  geom_density(aes(color = City, fill = City), alpha = 0.3) + # if you are mapping a variable (i.e. alpha = 0.3) it should be in aes(). alpha determines if it is opaque or transparent 0 = lines, 1 = filled in 
  scale_x_continuous(limits = c(0, 3e6)) # changes conditions of the x axis variables for continuous variables (if your variable was discrete you would use 'scale_x_discrete')

```

There is a higher density (higher peak of houses sold at lower prices) for homes in Santa Maria. This aligns with what we saw in the summary statistics. 


Explore the relationship (visual data exploration) between square footage and home price. Change the point COLOR by City, and the point shape by sale status.

```{r}
ggplot(data = homes_sub, aes(x = SqFt, y = Price)) +
  geom_point() +
  geom_smooth(method = "lm")
```
The outlier could be explained by multiple reasons we don't know: it's a celebrities home, the amount of land it is sitting on, it could be updated, or it could have a high value location (i.e. on the water).

## Model the relationship with homes as price as DV (dependent variable)

```{r}
homes_lm1 <- lm(Price ~ City + Bedrooms + Bathrooms + SqFt + PricePerSqFt + Status, data = homes_sub)
# you have multiple things telling you the same thing in this line of code (i.e. PricePerSqFt should be a red flag/ bedrooms and bathrooms are closely related)

# Make a subset that only contains the quantitative variables
homes_quant <- homes_sub %>% 
  select(Price:PricePerSqFt) # get a verison of the home_sub that only contains versions of the quantitative variables

homes_cor <- cor(homes_quant)
homes_cor

corrplot(homes_cor, method = 'ellipse')

# Call homes_lm1 in the console
# Bedrooms and bathrooms are moderately positively correlated 
# Reference level is OroGrande (the one that doesn't show up). Foreclosure is the reference status. There are enough variables in here that don't make sense that you should worry about what seems redundant. 

# How would I explore diagnostic plots?
plot(homes_lm1)
```
Try another model (homes_lm2), where we simplify this a bit:

- City
- SqFt
- Status

```{r}
homes_lm2 <- lm(Price ~ City + SqFt + Status, data = homes_sub)

# Call homes_lm2 in the console

plot(homes_lm2)

# Call on 'summary(homes_lm1)' in the console
# Adjusted R-squared is what you use when you do multiple linear regression because model fit will account for the adding more variables. 
# Adjusted R- squared = 0.8457. Meaning 84% of variance in home price is explained by the predictor variables in this model. 

```
Find the AIC value of each model:

```{r}
AIC(homes_lm1)
AIC(homes_lm2)

# Lower AIC represent better balance of fit and complexity
```

Try another permutation of this model that you think might make sense, check out & compare the model fit, outputs and AIC value.

```{r}
homes_lm3 <- lm(Price ~ SqFt + City + Status + Bedrooms, data = homes_sub)

summary(homes_lm3)
AIC(homes_lm3)

# Property size (acerage) seems critical to include 
```

Use 'modelsummary' to show model outputs side-by-side

If you use modelsummary to return model outputs of multiple models, it wants you to feed it to it as a list
```{r}
# modelsummary(homes_lm1)
modelsummary(list(homes_lm1, homes_lm2, homes_lm3))
```

## Start making predictions with this model

Use 'broom::augment()'

```{r}
homes_predicted <- augment(homes_lm1)
```

Use 'predict()' function to try out your model on new scenarios that you create.

# MY UPDATE!!!!

This is really obvious